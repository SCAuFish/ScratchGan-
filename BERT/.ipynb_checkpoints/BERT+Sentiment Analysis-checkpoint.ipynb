{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Initializing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow version: 2.1.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"Using Tensorflow version: \" + tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "BERT_DIR = \"/home/aufish/Downloads/bert\"\n",
    "\n",
    "# try with TF2 SavedModel\n",
    "# The online downloading method does not work, use pre-downloaded module\n",
    "# bert_module = hub.Module(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\")\n",
    "\n",
    "bert_module = hub.KerasLayer(BERT_DIR, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from bert import tokenization\n",
    "\n",
    "def create_tokenizer(vocab_file, do_lower_case=False):\n",
    "    return tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer(BERT_DIR + \"/assets/vocab.txt\")\n",
    "\n",
    "def convert_sentence_to_features(sentence, tokenizer, max_seq_len=50):\n",
    "    tokens = ['[CLS]']\n",
    "    tokens.extend(tokenizer.tokenize(sentence))\n",
    "    if len(tokens) > max_seq_len-1:\n",
    "        tokens = tokens[:max_seq_len-1]\n",
    "    tokens.append('[SEP]')\n",
    "    \n",
    "    segment_ids = [0] * len(tokens)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    #Zero Mask till seq_length\n",
    "    zero_mask = [0] * (max_seq_len-len(tokens))\n",
    "    input_ids.extend(zero_mask)\n",
    "    input_mask.extend(zero_mask)\n",
    "    segment_ids.extend(zero_mask)\n",
    "    \n",
    "    return input_ids, input_mask, segment_ids\n",
    "\n",
    "def convert_sentences_to_features(sentences, tokenizer, max_seq_len=50):\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len)\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_input_mask.append(input_mask)\n",
    "        all_segment_ids.append(segment_ids)\n",
    "    \n",
    "    return all_input_ids, all_input_mask, all_segment_ids\n",
    "\n",
    "import random, copy\n",
    "import numpy as np\n",
    "def make_rand_mask(input_ids, input_mask, vocab_size, segment_id_vals=None):\n",
    "    ''' \n",
    "    input_ids: the ids of words in the sentences\n",
    "    input_mask: initial mask (1 if there is a word; 0 for padding)\n",
    "    returns\n",
    "    input_mask: replace one bit of 1 with 0, meaning that the word will be masked\n",
    "    mask_word_ids: the id of words that are masked\n",
    "    pure_ids: ids in number instead of one-hot (to generate weights per masked word)\n",
    "    segment_id_vals: mark the masked word with segment id 1\n",
    "    '''\n",
    "    batch_size = len(input_ids)\n",
    "    \n",
    "    new_input_mask = copy.deepcopy(input_mask)\n",
    "    mask_word_ids = np.zeros((batch_size, vocab_size))\n",
    "    pure_ids = []\n",
    "    segment_encodings = []\n",
    "    for i in range(batch_size):\n",
    "        total_word = sum(input_mask[i])\n",
    "        mask_word = random.randint(0, total_word-1)\n",
    "        \n",
    "        pure_ids.append(input_ids[i][mask_word])\n",
    "        assert new_input_mask[i][mask_word] == 1\n",
    "        new_input_mask[i][mask_word] = 0\n",
    "        mask_word_ids[i][input_ids[i][mask_word]] = 1.0\n",
    "        \n",
    "        # Make the masked word segment id 1\n",
    "        assert segment_id_vals[i][mask_word] == 0\n",
    "        segment_id_vals[i][mask_word] = 1\n",
    "                \n",
    "    return new_input_mask, tf.convert_to_tensor(mask_word_ids, dtype=tf.dtypes.float32), pure_ids, segment_id_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentBert(tf.keras.Model):\n",
    "    def __init__(self, class_num, bert=bert_module, dropout=0.1):\n",
    "        super(SentimentBert, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.drop1 = tf.keras.layers.Dropout(rate=dropout, trainable=True)\n",
    "        self.dense1 = tf.keras.layers.Dense(\n",
    "            256,\n",
    "            activation=tf.keras.activations.relu,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='sentiment_classification_hidden',\n",
    "            trainable=True)\n",
    "        \n",
    "        self.drop2 = tf.keras.layers.Dropout(rate=dropout, trainable=True)\n",
    "        self.dense2 = tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=None,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='sentiment_classification',\n",
    "            trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # When passed in, all tensors are stacked in one, split it into a list\n",
    "        inputs = tf.unstack(tf.cast(inputs, tf.dtypes.int32), axis=1)\n",
    "        pooled, sequential = self.bert(inputs)\n",
    "        x = self.drop1(pooled)\n",
    "        x = self.dense1(x)\n",
    "        x = self.drop2(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Sanity test on creating and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentBert(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_model/word_embeddings/embeddings:0\n",
      "bert_model/embedding_postprocessor/type_embeddings:0\n",
      "bert_model/embedding_postprocessor/position_embeddings:0\n",
      "bert_model/embedding_postprocessor/layer_norm/gamma:0\n",
      "bert_model/embedding_postprocessor/layer_norm/beta:0\n",
      "bert_model/encoder/layer_0/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_0/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_0/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_0/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_0/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_0/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_0/intermediate/kernel:0\n",
      "bert_model/encoder/layer_0/intermediate/bias:0\n",
      "bert_model/encoder/layer_0/output/kernel:0\n",
      "bert_model/encoder/layer_0/output/bias:0\n",
      "bert_model/encoder/layer_0/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_0/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_1/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_1/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_1/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_1/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_1/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_1/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_1/intermediate/kernel:0\n",
      "bert_model/encoder/layer_1/intermediate/bias:0\n",
      "bert_model/encoder/layer_1/output/kernel:0\n",
      "bert_model/encoder/layer_1/output/bias:0\n",
      "bert_model/encoder/layer_1/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_1/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_2/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_2/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_2/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_2/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_2/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_2/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_2/intermediate/kernel:0\n",
      "bert_model/encoder/layer_2/intermediate/bias:0\n",
      "bert_model/encoder/layer_2/output/kernel:0\n",
      "bert_model/encoder/layer_2/output/bias:0\n",
      "bert_model/encoder/layer_2/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_2/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_3/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_3/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_3/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_3/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_3/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_3/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_3/intermediate/kernel:0\n",
      "bert_model/encoder/layer_3/intermediate/bias:0\n",
      "bert_model/encoder/layer_3/output/kernel:0\n",
      "bert_model/encoder/layer_3/output/bias:0\n",
      "bert_model/encoder/layer_3/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_3/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_4/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_4/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_4/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_4/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_4/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_4/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_4/intermediate/kernel:0\n",
      "bert_model/encoder/layer_4/intermediate/bias:0\n",
      "bert_model/encoder/layer_4/output/kernel:0\n",
      "bert_model/encoder/layer_4/output/bias:0\n",
      "bert_model/encoder/layer_4/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_4/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_5/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_5/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_5/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_5/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_5/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_5/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_5/intermediate/kernel:0\n",
      "bert_model/encoder/layer_5/intermediate/bias:0\n",
      "bert_model/encoder/layer_5/output/kernel:0\n",
      "bert_model/encoder/layer_5/output/bias:0\n",
      "bert_model/encoder/layer_5/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_5/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_6/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_6/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_6/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_6/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_6/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_6/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_6/intermediate/kernel:0\n",
      "bert_model/encoder/layer_6/intermediate/bias:0\n",
      "bert_model/encoder/layer_6/output/kernel:0\n",
      "bert_model/encoder/layer_6/output/bias:0\n",
      "bert_model/encoder/layer_6/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_6/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_7/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_7/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_7/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_7/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_7/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_7/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_7/intermediate/kernel:0\n",
      "bert_model/encoder/layer_7/intermediate/bias:0\n",
      "bert_model/encoder/layer_7/output/kernel:0\n",
      "bert_model/encoder/layer_7/output/bias:0\n",
      "bert_model/encoder/layer_7/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_7/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_8/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_8/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_8/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_8/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_8/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_8/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_8/intermediate/kernel:0\n",
      "bert_model/encoder/layer_8/intermediate/bias:0\n",
      "bert_model/encoder/layer_8/output/kernel:0\n",
      "bert_model/encoder/layer_8/output/bias:0\n",
      "bert_model/encoder/layer_8/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_8/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_9/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_9/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_9/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_9/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_9/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_9/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_9/intermediate/kernel:0\n",
      "bert_model/encoder/layer_9/intermediate/bias:0\n",
      "bert_model/encoder/layer_9/output/kernel:0\n",
      "bert_model/encoder/layer_9/output/bias:0\n",
      "bert_model/encoder/layer_9/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_9/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_10/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_10/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_10/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_10/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_10/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_10/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_10/intermediate/kernel:0\n",
      "bert_model/encoder/layer_10/intermediate/bias:0\n",
      "bert_model/encoder/layer_10/output/kernel:0\n",
      "bert_model/encoder/layer_10/output/bias:0\n",
      "bert_model/encoder/layer_10/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_10/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_11/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_11/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_11/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_11/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_11/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_11/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_11/intermediate/kernel:0\n",
      "bert_model/encoder/layer_11/intermediate/bias:0\n",
      "bert_model/encoder/layer_11/output/kernel:0\n",
      "bert_model/encoder/layer_11/output/bias:0\n",
      "bert_model/encoder/layer_11/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_11/output_layer_norm/beta:0\n",
      "bert_model/pooler_transform/kernel:0\n",
      "bert_model/pooler_transform/bias:0\n"
     ]
    }
   ],
   "source": [
    "for weight in model.trainable_weights:\n",
    "    print(weight.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2 = tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=None,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='sentiment_classification',\n",
    "            trainable=True, input_shape=(16,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 239232\n"
     ]
    }
   ],
   "source": [
    "# Get the sentiment score of each phrase and write out to a file\n",
    "DATASET_DIR = \"/home/aufish/Downloads/stanfordSentimentTreebank\"\n",
    "\n",
    "score_file = open(DATASET_DIR + \"/sentiment_labels.txt\", \"r\")\n",
    "score_dict = dict()\n",
    "\n",
    "for line in score_file.readlines():\n",
    "    parts = line.split(\"|\")\n",
    "    if parts[0] == \"phrase ids\":\n",
    "        # skip first header line\n",
    "        continue\n",
    "        \n",
    "    phrase_id, score = parts[0], float(parts[1])\n",
    "    score_dict[phrase_id] = score\n",
    "    \n",
    "score_file.close()\n",
    "\n",
    "phrase_file = open(DATASET_DIR + \"/dictionary.txt\", \"r\")\n",
    "phrase_score_file = open(\"./phrase_score.txt\", \"w\")\n",
    "\n",
    "for line in phrase_file.readlines():\n",
    "    parts = line.split(\"|\")\n",
    "    \n",
    "    score = score_dict[parts[1].strip()]\n",
    "    \n",
    "    phrase_score_file.write(\"{}|{}\\n\".format(parts[0], str(score)) )\n",
    "    \n",
    "phrase_file.close()\n",
    "phrase_score_file.close()\n",
    "\n",
    "print(\"Dataset size: {}\".format(len(score_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load into Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parse_line(line):\n",
    "    parts = line.split(b\"|\")\n",
    "    phrase, score = parts[0].decode(), float(parts[1].decode())\n",
    "    \n",
    "    input_ids, input_mask, segment_ids = convert_sentence_to_features(phrase, tokenizer, max_seq_len=20)\n",
    "        \n",
    "    return ([input_ids, input_mask, segment_ids], score)\n",
    "\n",
    "def create_dataset(filename = \"./phrase_score.txt\", data_size=239232, batch_size=10):\n",
    "    dataset = tf.data.TextLineDataset([filename]) \n",
    "\n",
    "    dataset = dataset.map(lambda x: tf.numpy_function(parse_line, [x], [tf.int64, tf.double]))\n",
    "\n",
    "    # dataset = dataset.shuffle(data_size, reshuffle_each_iteration=False)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test what is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[101 106 102 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 106 112 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 106 112 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[101 106 136 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 106 136 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 108 102 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]], shape=(20, 3, 20), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0.5     0.52778 0.5     0.44444 0.86111 0.93056 1.      0.47222 0.76389\n",
      " 0.27778 0.5     0.43056 0.5     0.22222 0.55556 0.77778 0.63889 0.5\n",
      " 0.5     0.5    ], shape=(20,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[101 106 102 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 106 112 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 106 112 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[101 106 136 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 106 136 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[101 108 102 ...   0   0   0]\n",
      "  [  1   1   1 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]], shape=(20, 3, 20), dtype=int32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6a6f844eb2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbert_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for (bert_input, target) in dataset.take(5):\n",
    "    print(bert_input)\n",
    "    print(target)\n",
    "    bert_input = tf.cast(bert_input, tf.dtypes.int32)\n",
    "    print(bert_input)\n",
    "    model(bert_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 standardize_input_data\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 <listcomp>\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:451 standardize_single_array\n        if (x.shape is not None and len(x.shape) == 1 and\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/tensor_shape.py:822 __len__\n        raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n\n    ValueError: Cannot take the length of shape with unknown rank.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-90d7715a43a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 standardize_input_data\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 <listcomp>\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:451 standardize_single_array\n        if (x.shape is not None and len(x.shape) == 1 and\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/tensor_shape.py:822 __len__\n        raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n\n    ValueError: Cannot take the length of shape with unknown rank.\n"
     ]
    }
   ],
   "source": [
    "# Fit function has bug\n",
    "model = SentimentBert(1)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n",
    "model.fit(x=dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentBert(1)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "bce_loss= tf.keras.losses.MeanSquaredError()\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_model/word_embeddings/embeddings:0\n",
      "bert_model/embedding_postprocessor/type_embeddings:0\n",
      "bert_model/embedding_postprocessor/position_embeddings:0\n",
      "bert_model/embedding_postprocessor/layer_norm/gamma:0\n",
      "bert_model/embedding_postprocessor/layer_norm/beta:0\n",
      "bert_model/encoder/layer_0/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_0/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_0/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_0/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_0/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_0/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_0/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_0/intermediate/kernel:0\n",
      "bert_model/encoder/layer_0/intermediate/bias:0\n",
      "bert_model/encoder/layer_0/output/kernel:0\n",
      "bert_model/encoder/layer_0/output/bias:0\n",
      "bert_model/encoder/layer_0/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_0/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_1/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_1/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_1/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_1/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_1/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_1/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_1/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_1/intermediate/kernel:0\n",
      "bert_model/encoder/layer_1/intermediate/bias:0\n",
      "bert_model/encoder/layer_1/output/kernel:0\n",
      "bert_model/encoder/layer_1/output/bias:0\n",
      "bert_model/encoder/layer_1/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_1/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_2/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_2/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_2/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_2/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_2/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_2/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_2/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_2/intermediate/kernel:0\n",
      "bert_model/encoder/layer_2/intermediate/bias:0\n",
      "bert_model/encoder/layer_2/output/kernel:0\n",
      "bert_model/encoder/layer_2/output/bias:0\n",
      "bert_model/encoder/layer_2/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_2/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_3/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_3/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_3/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_3/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_3/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_3/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_3/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_3/intermediate/kernel:0\n",
      "bert_model/encoder/layer_3/intermediate/bias:0\n",
      "bert_model/encoder/layer_3/output/kernel:0\n",
      "bert_model/encoder/layer_3/output/bias:0\n",
      "bert_model/encoder/layer_3/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_3/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_4/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_4/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_4/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_4/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_4/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_4/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_4/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_4/intermediate/kernel:0\n",
      "bert_model/encoder/layer_4/intermediate/bias:0\n",
      "bert_model/encoder/layer_4/output/kernel:0\n",
      "bert_model/encoder/layer_4/output/bias:0\n",
      "bert_model/encoder/layer_4/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_4/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_5/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_5/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_5/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_5/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_5/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_5/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_5/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_5/intermediate/kernel:0\n",
      "bert_model/encoder/layer_5/intermediate/bias:0\n",
      "bert_model/encoder/layer_5/output/kernel:0\n",
      "bert_model/encoder/layer_5/output/bias:0\n",
      "bert_model/encoder/layer_5/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_5/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_6/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_6/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_6/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_6/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_6/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_6/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_6/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_6/intermediate/kernel:0\n",
      "bert_model/encoder/layer_6/intermediate/bias:0\n",
      "bert_model/encoder/layer_6/output/kernel:0\n",
      "bert_model/encoder/layer_6/output/bias:0\n",
      "bert_model/encoder/layer_6/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_6/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_7/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_7/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_7/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_7/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_7/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_7/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_7/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_7/intermediate/kernel:0\n",
      "bert_model/encoder/layer_7/intermediate/bias:0\n",
      "bert_model/encoder/layer_7/output/kernel:0\n",
      "bert_model/encoder/layer_7/output/bias:0\n",
      "bert_model/encoder/layer_7/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_7/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_8/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_8/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_8/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_8/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_8/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_8/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_8/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_8/intermediate/kernel:0\n",
      "bert_model/encoder/layer_8/intermediate/bias:0\n",
      "bert_model/encoder/layer_8/output/kernel:0\n",
      "bert_model/encoder/layer_8/output/bias:0\n",
      "bert_model/encoder/layer_8/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_8/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_9/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_9/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_9/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_9/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_9/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_9/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_9/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_9/intermediate/kernel:0\n",
      "bert_model/encoder/layer_9/intermediate/bias:0\n",
      "bert_model/encoder/layer_9/output/kernel:0\n",
      "bert_model/encoder/layer_9/output/bias:0\n",
      "bert_model/encoder/layer_9/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_9/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_10/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_10/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_10/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_10/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_10/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_10/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_10/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_10/intermediate/kernel:0\n",
      "bert_model/encoder/layer_10/intermediate/bias:0\n",
      "bert_model/encoder/layer_10/output/kernel:0\n",
      "bert_model/encoder/layer_10/output/bias:0\n",
      "bert_model/encoder/layer_10/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_10/output_layer_norm/beta:0\n",
      "bert_model/encoder/layer_11/self_attention/query/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention/query/bias:0\n",
      "bert_model/encoder/layer_11/self_attention/key/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention/key/bias:0\n",
      "bert_model/encoder/layer_11/self_attention/value/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention/value/bias:0\n",
      "bert_model/encoder/layer_11/self_attention_output/kernel:0\n",
      "bert_model/encoder/layer_11/self_attention_output/bias:0\n",
      "bert_model/encoder/layer_11/self_attention_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_11/self_attention_layer_norm/beta:0\n",
      "bert_model/encoder/layer_11/intermediate/kernel:0\n",
      "bert_model/encoder/layer_11/intermediate/bias:0\n",
      "bert_model/encoder/layer_11/output/kernel:0\n",
      "bert_model/encoder/layer_11/output/bias:0\n",
      "bert_model/encoder/layer_11/output_layer_norm/gamma:0\n",
      "bert_model/encoder/layer_11/output_layer_norm/beta:0\n",
      "bert_model/pooler_transform/kernel:0\n",
      "bert_model/pooler_transform/bias:0\n"
     ]
    }
   ],
   "source": [
    "for weight in model.trainable_weights:\n",
    "    print(weight.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = tf.Tensor(0.74190927, shape=(), dtype=float32)\n",
      "step 1000: mean loss = tf.Tensor(0.64430064, shape=(), dtype=float32)\n",
      "step 2000: mean loss = tf.Tensor(0.65155405, shape=(), dtype=float32)\n",
      "step 3000: mean loss = tf.Tensor(0.6521434, shape=(), dtype=float32)\n",
      "step 4000: mean loss = tf.Tensor(0.6512532, shape=(), dtype=float32)\n",
      "step 5000: mean loss = tf.Tensor(0.6524354, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b1f9ba3695ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0;31m# Compute reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add KLD regularization loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    124\u001b[0m         y_true, y_pred, sample_weight)\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    128\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m   \u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   1961\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[1;32m   1963\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    total_loss = 0\n",
    "    for step, (bert_input, target) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "          output = model(bert_input)\n",
    "          # Compute reconstruction loss\n",
    "          loss = bce_loss(target, output)\n",
    "          loss += sum(model.losses)  # Add KLD regularization loss\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "          print('step %s: mean loss = %s' % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./bert_sentiment_analysis_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    # Give a sentence and return the sentiment score of the sentence\n",
    "    input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len=20)\n",
    "    tensor_input = tf.stack([tf.constant(input_ids), tf.constant(input_mask), tf.constant(segment_ids)])\n",
    "    tensor_input = tf.reshape(tensor_input, [1, 3, 20])\n",
    "    \n",
    "    return model(tensor_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5123083]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
