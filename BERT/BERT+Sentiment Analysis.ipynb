{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Initializing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow version: 2.1.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"Using Tensorflow version: \" + tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "BERT_DIR = \"/home/aufish/Downloads/bert\"\n",
    "\n",
    "# try with TF2 SavedModel\n",
    "# The online downloading method does not work, use pre-downloaded module\n",
    "# bert_module = hub.Module(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\")\n",
    "\n",
    "bert_module = hub.KerasLayer(BERT_DIR, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from bert import tokenization\n",
    "\n",
    "def create_tokenizer(vocab_file, do_lower_case=False):\n",
    "    return tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer(BERT_DIR + \"/assets/vocab.txt\")\n",
    "\n",
    "def convert_sentence_to_features(sentence, tokenizer, max_seq_len=50):\n",
    "    tokens = ['[CLS]']\n",
    "    tokens.extend(tokenizer.tokenize(sentence))\n",
    "    if len(tokens) > max_seq_len-1:\n",
    "        tokens = tokens[:max_seq_len-1]\n",
    "    tokens.append('[SEP]')\n",
    "    \n",
    "    segment_ids = [0] * len(tokens)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    #Zero Mask till seq_length\n",
    "    zero_mask = [0] * (max_seq_len-len(tokens))\n",
    "    input_ids.extend(zero_mask)\n",
    "    input_mask.extend(zero_mask)\n",
    "    segment_ids.extend(zero_mask)\n",
    "    \n",
    "    return input_ids, input_mask, segment_ids\n",
    "\n",
    "def convert_sentences_to_features(sentences, tokenizer, max_seq_len=50):\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len)\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_input_mask.append(input_mask)\n",
    "        all_segment_ids.append(segment_ids)\n",
    "    \n",
    "    return all_input_ids, all_input_mask, all_segment_ids\n",
    "\n",
    "import random, copy\n",
    "import numpy as np\n",
    "def make_rand_mask(input_ids, input_mask, vocab_size, segment_id_vals=None):\n",
    "    ''' \n",
    "    input_ids: the ids of words in the sentences\n",
    "    input_mask: initial mask (1 if there is a word; 0 for padding)\n",
    "    returns\n",
    "    input_mask: replace one bit of 1 with 0, meaning that the word will be masked\n",
    "    mask_word_ids: the id of words that are masked\n",
    "    pure_ids: ids in number instead of one-hot (to generate weights per masked word)\n",
    "    segment_id_vals: mark the masked word with segment id 1\n",
    "    '''\n",
    "    batch_size = len(input_ids)\n",
    "    \n",
    "    new_input_mask = copy.deepcopy(input_mask)\n",
    "    mask_word_ids = np.zeros((batch_size, vocab_size))\n",
    "    pure_ids = []\n",
    "    segment_encodings = []\n",
    "    for i in range(batch_size):\n",
    "        total_word = sum(input_mask[i])\n",
    "        mask_word = random.randint(0, total_word-1)\n",
    "        \n",
    "        pure_ids.append(input_ids[i][mask_word])\n",
    "        assert new_input_mask[i][mask_word] == 1\n",
    "        new_input_mask[i][mask_word] = 0\n",
    "        mask_word_ids[i][input_ids[i][mask_word]] = 1.0\n",
    "        \n",
    "        # Make the masked word segment id 1\n",
    "        assert segment_id_vals[i][mask_word] == 0\n",
    "        segment_id_vals[i][mask_word] = 1\n",
    "                \n",
    "    return new_input_mask, tf.convert_to_tensor(mask_word_ids, dtype=tf.dtypes.float32), pure_ids, segment_id_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentBert(tf.keras.Model):\n",
    "    def __init__(self, class_num, bert=bert_module, dropout=0.1):\n",
    "        super(SentimentBert, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.drop = tf.keras.layers.Dropout(rate=dropout)\n",
    "        self.dense= tf.keras.layers.Dense(\n",
    "            class_num,\n",
    "            activation=tf.keras.activations.sigmoid,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='sentiment_classification')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # When passed in, all tensors are stacked in one, split it into a list\n",
    "        inputs = tf.unstack(tf.cast(inputs, tf.dtypes.int32), axis=1)\n",
    "        pooled, sequential = self.bert(inputs)\n",
    "        x = self.drop(pooled)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Sanity test on creating and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentBert(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 239232\n"
     ]
    }
   ],
   "source": [
    "# Get the sentiment score of each phrase and write out to a file\n",
    "DATASET_DIR = \"/home/aufish/Downloads/stanfordSentimentTreebank\"\n",
    "\n",
    "score_file = open(DATASET_DIR + \"/sentiment_labels.txt\", \"r\")\n",
    "score_dict = dict()\n",
    "\n",
    "for line in score_file.readlines():\n",
    "    parts = line.split(\"|\")\n",
    "    if parts[0] == \"phrase ids\":\n",
    "        # skip first header line\n",
    "        continue\n",
    "        \n",
    "    phrase_id, score = parts[0], float(parts[1])\n",
    "    score_dict[phrase_id] = score\n",
    "    \n",
    "score_file.close()\n",
    "\n",
    "phrase_file = open(DATASET_DIR + \"/dictionary.txt\", \"r\")\n",
    "phrase_score_file = open(\"./phrase_score.txt\", \"w\")\n",
    "\n",
    "for line in phrase_file.readlines():\n",
    "    parts = line.split(\"|\")\n",
    "    \n",
    "    score = score_dict[parts[1].strip()]\n",
    "    \n",
    "    phrase_score_file.write(\"{}|{}\\n\".format(parts[0], str(score)) )\n",
    "    \n",
    "phrase_file.close()\n",
    "phrase_score_file.close()\n",
    "\n",
    "print(\"Dataset size: {}\".format(len(score_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load into Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parse_line(line):\n",
    "    parts = line.split(b\"|\")\n",
    "    phrase, score = parts[0].decode(), float(parts[1].decode())\n",
    "    \n",
    "    input_ids, input_mask, segment_ids = convert_sentence_to_features(phrase, tokenizer, max_seq_len=20)\n",
    "        \n",
    "    return ([input_ids, input_mask, segment_ids], score)\n",
    "\n",
    "def create_dataset(filename = \"./phrase_score.txt\", data_size=239232, batch_size=10):\n",
    "    dataset = tf.data.TextLineDataset([filename]) \n",
    "\n",
    "    dataset = dataset.map(lambda x: tf.numpy_function(parse_line, [x], [tf.int64, tf.double]))\n",
    "\n",
    "    # dataset = dataset.shuffle(data_size, reshuffle_each_iteration=False)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test what is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  101   106   102     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   112   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   112   112   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  2586  2225   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   139 11071 13789   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   139 11071 13789   106   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   139 11071 13789   106   112   102     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   140   112 19863   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  3414 21275   112   188   169  2099   112  1110 10965\n",
      "     102     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  2048   117  1440  1120  1115 13336  6341   106 11750\n",
      "     117   170  5152  2195   106   102     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     1     1     1     1     1     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[  101   106   102     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   112   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   112   112   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  2586  2225   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   139 11071 13789   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   139 11071 13789   106   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   139 11071 13789   106   112   102     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   140   112 19863   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  3414 21275   112   188   169  2099   112  1110 10965\n",
      "     102     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  2048   117  1440  1120  1115 13336  6341   106 11750\n",
      "     117   170  5152  2195   106   102     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     1     1     1     1     1     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[  101   106  3352 25202   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  6728   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  1109  8275   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  1109  4504   189 26137  1116   106  2048   117  1440\n",
      "    1120  1115 13336  6341   106 11750   117   170   102]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     1     1     1     1     1     1     1     1]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  7817  4613  5145   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106 11750   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106 13899  1306   106   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   136   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   136   112   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108   102     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[  101   106  3352 25202   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  6728   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  1109  8275   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  1109  4504   189 26137  1116   106  2048   117  1440\n",
      "    1120  1115 13336  6341   106 11750   117   170   102]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     1     1     1     1     1     1     1     1]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106  7817  4613  5145   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106 11750   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106 13899  1306   106   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   136   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   106   136   112   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108   102     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[  101   108 15118   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108   124   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108  5787 16770   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108  5787 16770   132   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108  5787 16770   132   189   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108   130   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   102     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   122   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   122   119   129   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   122   119   129  1550   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[  101   108 15118   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108   124   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108  5787 16770   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108  5787 16770   132   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108  5787 16770   132   189   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   108   130   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   102     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   122   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   122   119   129   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   122   119   129  1550   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[  101   109   122   119   129  1550 11967  1200   102     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1620   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1620  1550   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1620  1550  1113  1142   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1406   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1406  1550   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1406  1550  7260  1106  4176   170  1938  8964   102\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1969   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1969  1550   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1969  1550  1683   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[  101   109   122   119   129  1550 11967  1200   102     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1620   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1620  1550   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1620  1550  1113  1142   102     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1406   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1406  1550   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1406  1550  7260  1106  4176   170  1938  8964   102\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1969   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1969  1550   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1969  1550  1683   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[  101   109  1851   118  1550   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1851   118  1550  1646  4788   102     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   128   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   128   119  3135   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   129   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130  1105   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130  1105  5429  1904  1104  8362  1874 17800  1895\n",
      "    1297   102     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     1     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130   119  1851   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  4850   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[  101   109  1851   118  1550   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  1851   118  1550  1646  4788   102     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   128   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   128   119  3135   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   129   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130  1105   102     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130  1105  5429  1904  1104  8362  1874 17800  1895\n",
      "    1297   102     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     1     1     1     1     1\n",
      "       1     1     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109   130   119  1851   102     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     1     1     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]\n",
      "\n",
      " [[  101   109  4850   102     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    1     1     1     1     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]\n",
      "  [    0     0     0     0     0     0     0     0     0     0     0\n",
      "       0     0     0     0     0     0     0     0     0]]], shape=(10, 3, 20), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for (bert_input, target) in dataset.take(5):\n",
    "    print(bert_input)\n",
    "    print(target)\n",
    "    bert_input = tf.cast(bert_input, tf.dtypes.int32)\n",
    "    print(bert_input)\n",
    "    model(bert_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 standardize_input_data\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 <listcomp>\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:451 standardize_single_array\n        if (x.shape is not None and len(x.shape) == 1 and\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/tensor_shape.py:822 __len__\n        raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n\n    ValueError: Cannot take the length of shape with unknown rank.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-90d7715a43a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 standardize_input_data\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:529 <listcomp>\n        data = [standardize_single_array(x) for x in data]\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:451 standardize_single_array\n        if (x.shape is not None and len(x.shape) == 1 and\n    /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/tensor_shape.py:822 __len__\n        raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n\n    ValueError: Cannot take the length of shape with unknown rank.\n"
     ]
    }
   ],
   "source": [
    "# Fit function has bug\n",
    "model = SentimentBert(1)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n",
    "model.fit(x=dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = tf.Tensor(0.1469778, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.034767933, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.035866126, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.03909982, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.039109845, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.038421936, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.036577944, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.03744269, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.03675551, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.037878055, shape=(), dtype=float32)\n",
      "step 1000: mean loss = tf.Tensor(0.03760385, shape=(), dtype=float32)\n",
      "step 1100: mean loss = tf.Tensor(0.038826995, shape=(), dtype=float32)\n",
      "step 1200: mean loss = tf.Tensor(0.038181778, shape=(), dtype=float32)\n",
      "step 1300: mean loss = tf.Tensor(0.038149845, shape=(), dtype=float32)\n",
      "step 1400: mean loss = tf.Tensor(0.03830928, shape=(), dtype=float32)\n",
      "step 1500: mean loss = tf.Tensor(0.03952171, shape=(), dtype=float32)\n",
      "step 1600: mean loss = tf.Tensor(0.04061613, shape=(), dtype=float32)\n",
      "step 1700: mean loss = tf.Tensor(0.041411765, shape=(), dtype=float32)\n",
      "step 1800: mean loss = tf.Tensor(0.040926732, shape=(), dtype=float32)\n",
      "step 1900: mean loss = tf.Tensor(0.041050434, shape=(), dtype=float32)\n",
      "step 2000: mean loss = tf.Tensor(0.041117232, shape=(), dtype=float32)\n",
      "step 2100: mean loss = tf.Tensor(0.041045018, shape=(), dtype=float32)\n",
      "step 2200: mean loss = tf.Tensor(0.04036772, shape=(), dtype=float32)\n",
      "step 2300: mean loss = tf.Tensor(0.039878678, shape=(), dtype=float32)\n",
      "step 2400: mean loss = tf.Tensor(0.03926033, shape=(), dtype=float32)\n",
      "step 2500: mean loss = tf.Tensor(0.038849846, shape=(), dtype=float32)\n",
      "step 2600: mean loss = tf.Tensor(0.03868233, shape=(), dtype=float32)\n",
      "step 2700: mean loss = tf.Tensor(0.038286563, shape=(), dtype=float32)\n",
      "step 2800: mean loss = tf.Tensor(0.038458467, shape=(), dtype=float32)\n",
      "step 2900: mean loss = tf.Tensor(0.038270637, shape=(), dtype=float32)\n",
      "step 3000: mean loss = tf.Tensor(0.03801204, shape=(), dtype=float32)\n",
      "step 3100: mean loss = tf.Tensor(0.03772807, shape=(), dtype=float32)\n",
      "step 3200: mean loss = tf.Tensor(0.03765554, shape=(), dtype=float32)\n",
      "step 3300: mean loss = tf.Tensor(0.03787687, shape=(), dtype=float32)\n",
      "step 3400: mean loss = tf.Tensor(0.037864782, shape=(), dtype=float32)\n",
      "step 3500: mean loss = tf.Tensor(0.03832597, shape=(), dtype=float32)\n",
      "step 3600: mean loss = tf.Tensor(0.038735077, shape=(), dtype=float32)\n",
      "step 3700: mean loss = tf.Tensor(0.038223483, shape=(), dtype=float32)\n",
      "step 3800: mean loss = tf.Tensor(0.038005188, shape=(), dtype=float32)\n",
      "step 3900: mean loss = tf.Tensor(0.037779756, shape=(), dtype=float32)\n",
      "step 4000: mean loss = tf.Tensor(0.03746856, shape=(), dtype=float32)\n",
      "step 4100: mean loss = tf.Tensor(0.037166804, shape=(), dtype=float32)\n",
      "step 4200: mean loss = tf.Tensor(0.036956895, shape=(), dtype=float32)\n",
      "step 4300: mean loss = tf.Tensor(0.03694197, shape=(), dtype=float32)\n",
      "step 4400: mean loss = tf.Tensor(0.0371094, shape=(), dtype=float32)\n",
      "step 4500: mean loss = tf.Tensor(0.03689251, shape=(), dtype=float32)\n",
      "step 4600: mean loss = tf.Tensor(0.03666864, shape=(), dtype=float32)\n",
      "step 4700: mean loss = tf.Tensor(0.036438495, shape=(), dtype=float32)\n",
      "step 4800: mean loss = tf.Tensor(0.036393687, shape=(), dtype=float32)\n",
      "step 4900: mean loss = tf.Tensor(0.036414653, shape=(), dtype=float32)\n",
      "step 5000: mean loss = tf.Tensor(0.036347266, shape=(), dtype=float32)\n",
      "step 5100: mean loss = tf.Tensor(0.036368478, shape=(), dtype=float32)\n",
      "step 5200: mean loss = tf.Tensor(0.036499187, shape=(), dtype=float32)\n",
      "step 5300: mean loss = tf.Tensor(0.03672488, shape=(), dtype=float32)\n",
      "step 5400: mean loss = tf.Tensor(0.036868617, shape=(), dtype=float32)\n",
      "step 5500: mean loss = tf.Tensor(0.03697262, shape=(), dtype=float32)\n",
      "step 5600: mean loss = tf.Tensor(0.03717016, shape=(), dtype=float32)\n",
      "step 5700: mean loss = tf.Tensor(0.03734206, shape=(), dtype=float32)\n",
      "step 5800: mean loss = tf.Tensor(0.03724477, shape=(), dtype=float32)\n",
      "step 5900: mean loss = tf.Tensor(0.037106562, shape=(), dtype=float32)\n",
      "step 6000: mean loss = tf.Tensor(0.03708949, shape=(), dtype=float32)\n",
      "step 6100: mean loss = tf.Tensor(0.037056297, shape=(), dtype=float32)\n",
      "step 6200: mean loss = tf.Tensor(0.03697242, shape=(), dtype=float32)\n",
      "step 6300: mean loss = tf.Tensor(0.036862765, shape=(), dtype=float32)\n",
      "step 6400: mean loss = tf.Tensor(0.036809724, shape=(), dtype=float32)\n",
      "step 6500: mean loss = tf.Tensor(0.036749545, shape=(), dtype=float32)\n",
      "step 6600: mean loss = tf.Tensor(0.036761247, shape=(), dtype=float32)\n",
      "step 6700: mean loss = tf.Tensor(0.03670682, shape=(), dtype=float32)\n",
      "step 6800: mean loss = tf.Tensor(0.036690943, shape=(), dtype=float32)\n",
      "step 6900: mean loss = tf.Tensor(0.036686387, shape=(), dtype=float32)\n",
      "step 7000: mean loss = tf.Tensor(0.036628403, shape=(), dtype=float32)\n",
      "step 7100: mean loss = tf.Tensor(0.03666129, shape=(), dtype=float32)\n",
      "step 7200: mean loss = tf.Tensor(0.036629464, shape=(), dtype=float32)\n",
      "step 7300: mean loss = tf.Tensor(0.03642443, shape=(), dtype=float32)\n",
      "step 7400: mean loss = tf.Tensor(0.036250923, shape=(), dtype=float32)\n",
      "step 7500: mean loss = tf.Tensor(0.03604639, shape=(), dtype=float32)\n",
      "step 7600: mean loss = tf.Tensor(0.03596081, shape=(), dtype=float32)\n",
      "step 7700: mean loss = tf.Tensor(0.035922106, shape=(), dtype=float32)\n",
      "step 7800: mean loss = tf.Tensor(0.03593312, shape=(), dtype=float32)\n",
      "step 7900: mean loss = tf.Tensor(0.035761397, shape=(), dtype=float32)\n",
      "step 8000: mean loss = tf.Tensor(0.035604052, shape=(), dtype=float32)\n",
      "step 8100: mean loss = tf.Tensor(0.03553683, shape=(), dtype=float32)\n",
      "step 8200: mean loss = tf.Tensor(0.035487544, shape=(), dtype=float32)\n",
      "step 8300: mean loss = tf.Tensor(0.035346974, shape=(), dtype=float32)\n",
      "step 8400: mean loss = tf.Tensor(0.035220444, shape=(), dtype=float32)\n",
      "step 8500: mean loss = tf.Tensor(0.035064094, shape=(), dtype=float32)\n",
      "step 8600: mean loss = tf.Tensor(0.034996457, shape=(), dtype=float32)\n",
      "step 8700: mean loss = tf.Tensor(0.034920603, shape=(), dtype=float32)\n",
      "step 8800: mean loss = tf.Tensor(0.0348629, shape=(), dtype=float32)\n",
      "step 8900: mean loss = tf.Tensor(0.034774087, shape=(), dtype=float32)\n",
      "step 9000: mean loss = tf.Tensor(0.034639396, shape=(), dtype=float32)\n",
      "step 9100: mean loss = tf.Tensor(0.03459388, shape=(), dtype=float32)\n",
      "step 9200: mean loss = tf.Tensor(0.034518056, shape=(), dtype=float32)\n",
      "step 9300: mean loss = tf.Tensor(0.034417395, shape=(), dtype=float32)\n",
      "step 9400: mean loss = tf.Tensor(0.034345336, shape=(), dtype=float32)\n",
      "step 9500: mean loss = tf.Tensor(0.034224153, shape=(), dtype=float32)\n",
      "step 9600: mean loss = tf.Tensor(0.034144286, shape=(), dtype=float32)\n",
      "step 9700: mean loss = tf.Tensor(0.03407139, shape=(), dtype=float32)\n",
      "step 9800: mean loss = tf.Tensor(0.03400171, shape=(), dtype=float32)\n",
      "step 9900: mean loss = tf.Tensor(0.033908725, shape=(), dtype=float32)\n",
      "step 10000: mean loss = tf.Tensor(0.033881307, shape=(), dtype=float32)\n",
      "step 10100: mean loss = tf.Tensor(0.033772655, shape=(), dtype=float32)\n",
      "step 10200: mean loss = tf.Tensor(0.033735555, shape=(), dtype=float32)\n",
      "step 10300: mean loss = tf.Tensor(0.03370188, shape=(), dtype=float32)\n",
      "step 10400: mean loss = tf.Tensor(0.033637397, shape=(), dtype=float32)\n",
      "step 10500: mean loss = tf.Tensor(0.033583462, shape=(), dtype=float32)\n",
      "step 10600: mean loss = tf.Tensor(0.033546206, shape=(), dtype=float32)\n",
      "step 10700: mean loss = tf.Tensor(0.033524726, shape=(), dtype=float32)\n",
      "step 10800: mean loss = tf.Tensor(0.033456925, shape=(), dtype=float32)\n",
      "step 10900: mean loss = tf.Tensor(0.03343222, shape=(), dtype=float32)\n",
      "step 11000: mean loss = tf.Tensor(0.033324655, shape=(), dtype=float32)\n",
      "step 11100: mean loss = tf.Tensor(0.033244245, shape=(), dtype=float32)\n",
      "step 11200: mean loss = tf.Tensor(0.033149887, shape=(), dtype=float32)\n",
      "step 11300: mean loss = tf.Tensor(0.033073083, shape=(), dtype=float32)\n",
      "step 11400: mean loss = tf.Tensor(0.03293503, shape=(), dtype=float32)\n",
      "step 11500: mean loss = tf.Tensor(0.032801636, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11600: mean loss = tf.Tensor(0.03262478, shape=(), dtype=float32)\n",
      "step 11700: mean loss = tf.Tensor(0.03244583, shape=(), dtype=float32)\n",
      "step 11800: mean loss = tf.Tensor(0.032266498, shape=(), dtype=float32)\n",
      "step 11900: mean loss = tf.Tensor(0.03209871, shape=(), dtype=float32)\n",
      "step 12000: mean loss = tf.Tensor(0.031954087, shape=(), dtype=float32)\n",
      "step 12100: mean loss = tf.Tensor(0.031828947, shape=(), dtype=float32)\n",
      "step 12200: mean loss = tf.Tensor(0.031693105, shape=(), dtype=float32)\n",
      "step 12300: mean loss = tf.Tensor(0.031556983, shape=(), dtype=float32)\n",
      "step 12400: mean loss = tf.Tensor(0.03148336, shape=(), dtype=float32)\n",
      "step 12500: mean loss = tf.Tensor(0.031433456, shape=(), dtype=float32)\n",
      "step 12600: mean loss = tf.Tensor(0.03135305, shape=(), dtype=float32)\n",
      "step 12700: mean loss = tf.Tensor(0.031209001, shape=(), dtype=float32)\n",
      "step 12800: mean loss = tf.Tensor(0.031047657, shape=(), dtype=float32)\n",
      "step 12900: mean loss = tf.Tensor(0.030930385, shape=(), dtype=float32)\n",
      "step 13000: mean loss = tf.Tensor(0.030838998, shape=(), dtype=float32)\n",
      "step 13100: mean loss = tf.Tensor(0.030711347, shape=(), dtype=float32)\n",
      "step 13200: mean loss = tf.Tensor(0.030560326, shape=(), dtype=float32)\n",
      "step 13300: mean loss = tf.Tensor(0.030416632, shape=(), dtype=float32)\n",
      "step 13400: mean loss = tf.Tensor(0.03031171, shape=(), dtype=float32)\n",
      "step 13500: mean loss = tf.Tensor(0.030192228, shape=(), dtype=float32)\n",
      "step 13600: mean loss = tf.Tensor(0.03022057, shape=(), dtype=float32)\n",
      "step 13700: mean loss = tf.Tensor(0.030232536, shape=(), dtype=float32)\n",
      "step 13800: mean loss = tf.Tensor(0.030234838, shape=(), dtype=float32)\n",
      "step 13900: mean loss = tf.Tensor(0.03023481, shape=(), dtype=float32)\n",
      "step 14000: mean loss = tf.Tensor(0.03029461, shape=(), dtype=float32)\n",
      "step 14100: mean loss = tf.Tensor(0.03031949, shape=(), dtype=float32)\n",
      "step 14200: mean loss = tf.Tensor(0.030339662, shape=(), dtype=float32)\n",
      "step 14300: mean loss = tf.Tensor(0.030325329, shape=(), dtype=float32)\n",
      "step 14400: mean loss = tf.Tensor(0.030274611, shape=(), dtype=float32)\n",
      "step 14500: mean loss = tf.Tensor(0.030182887, shape=(), dtype=float32)\n",
      "step 14600: mean loss = tf.Tensor(0.03005702, shape=(), dtype=float32)\n",
      "step 14700: mean loss = tf.Tensor(0.02998076, shape=(), dtype=float32)\n",
      "step 14800: mean loss = tf.Tensor(0.02987896, shape=(), dtype=float32)\n",
      "step 14900: mean loss = tf.Tensor(0.029792776, shape=(), dtype=float32)\n",
      "step 15000: mean loss = tf.Tensor(0.029699294, shape=(), dtype=float32)\n",
      "step 15100: mean loss = tf.Tensor(0.02961282, shape=(), dtype=float32)\n",
      "step 15200: mean loss = tf.Tensor(0.02952702, shape=(), dtype=float32)\n",
      "step 15300: mean loss = tf.Tensor(0.029473064, shape=(), dtype=float32)\n",
      "step 15400: mean loss = tf.Tensor(0.029421762, shape=(), dtype=float32)\n",
      "step 15500: mean loss = tf.Tensor(0.029343225, shape=(), dtype=float32)\n",
      "step 15600: mean loss = tf.Tensor(0.029262334, shape=(), dtype=float32)\n",
      "step 15700: mean loss = tf.Tensor(0.029167982, shape=(), dtype=float32)\n",
      "step 15800: mean loss = tf.Tensor(0.029075626, shape=(), dtype=float32)\n",
      "step 15900: mean loss = tf.Tensor(0.028987825, shape=(), dtype=float32)\n",
      "step 16000: mean loss = tf.Tensor(0.028915778, shape=(), dtype=float32)\n",
      "step 16100: mean loss = tf.Tensor(0.028855303, shape=(), dtype=float32)\n",
      "step 16200: mean loss = tf.Tensor(0.028796948, shape=(), dtype=float32)\n",
      "step 16300: mean loss = tf.Tensor(0.02874372, shape=(), dtype=float32)\n",
      "step 16400: mean loss = tf.Tensor(0.028619751, shape=(), dtype=float32)\n",
      "step 16500: mean loss = tf.Tensor(0.028520826, shape=(), dtype=float32)\n",
      "step 16600: mean loss = tf.Tensor(0.02841603, shape=(), dtype=float32)\n",
      "step 16700: mean loss = tf.Tensor(0.028300887, shape=(), dtype=float32)\n",
      "step 16800: mean loss = tf.Tensor(0.02819829, shape=(), dtype=float32)\n",
      "step 16900: mean loss = tf.Tensor(0.028111547, shape=(), dtype=float32)\n",
      "step 17000: mean loss = tf.Tensor(0.028018348, shape=(), dtype=float32)\n",
      "step 17100: mean loss = tf.Tensor(0.027956143, shape=(), dtype=float32)\n",
      "step 17200: mean loss = tf.Tensor(0.027860634, shape=(), dtype=float32)\n",
      "step 17300: mean loss = tf.Tensor(0.027777031, shape=(), dtype=float32)\n",
      "step 17400: mean loss = tf.Tensor(0.027708717, shape=(), dtype=float32)\n",
      "step 17500: mean loss = tf.Tensor(0.027647719, shape=(), dtype=float32)\n",
      "step 17600: mean loss = tf.Tensor(0.027587982, shape=(), dtype=float32)\n",
      "step 17700: mean loss = tf.Tensor(0.027516678, shape=(), dtype=float32)\n",
      "step 17800: mean loss = tf.Tensor(0.02744487, shape=(), dtype=float32)\n",
      "step 17900: mean loss = tf.Tensor(0.02739361, shape=(), dtype=float32)\n",
      "step 18000: mean loss = tf.Tensor(0.027323877, shape=(), dtype=float32)\n",
      "step 18100: mean loss = tf.Tensor(0.027250377, shape=(), dtype=float32)\n",
      "step 18200: mean loss = tf.Tensor(0.027194522, shape=(), dtype=float32)\n",
      "step 18300: mean loss = tf.Tensor(0.02712508, shape=(), dtype=float32)\n",
      "step 18400: mean loss = tf.Tensor(0.027059797, shape=(), dtype=float32)\n",
      "step 18500: mean loss = tf.Tensor(0.02699651, shape=(), dtype=float32)\n",
      "step 18600: mean loss = tf.Tensor(0.026936976, shape=(), dtype=float32)\n",
      "step 18700: mean loss = tf.Tensor(0.02685549, shape=(), dtype=float32)\n",
      "step 18800: mean loss = tf.Tensor(0.026803572, shape=(), dtype=float32)\n",
      "step 18900: mean loss = tf.Tensor(0.02676029, shape=(), dtype=float32)\n",
      "step 19000: mean loss = tf.Tensor(0.026730733, shape=(), dtype=float32)\n",
      "step 19100: mean loss = tf.Tensor(0.026682148, shape=(), dtype=float32)\n",
      "step 19200: mean loss = tf.Tensor(0.026663637, shape=(), dtype=float32)\n",
      "step 19300: mean loss = tf.Tensor(0.026639977, shape=(), dtype=float32)\n",
      "step 19400: mean loss = tf.Tensor(0.026634099, shape=(), dtype=float32)\n",
      "step 19500: mean loss = tf.Tensor(0.026644, shape=(), dtype=float32)\n",
      "step 19600: mean loss = tf.Tensor(0.026675418, shape=(), dtype=float32)\n",
      "step 19700: mean loss = tf.Tensor(0.026670163, shape=(), dtype=float32)\n",
      "step 19800: mean loss = tf.Tensor(0.026667196, shape=(), dtype=float32)\n",
      "step 19900: mean loss = tf.Tensor(0.02663434, shape=(), dtype=float32)\n",
      "step 20000: mean loss = tf.Tensor(0.026655955, shape=(), dtype=float32)\n",
      "step 20100: mean loss = tf.Tensor(0.02665997, shape=(), dtype=float32)\n",
      "step 20200: mean loss = tf.Tensor(0.02662717, shape=(), dtype=float32)\n",
      "step 20300: mean loss = tf.Tensor(0.026556447, shape=(), dtype=float32)\n",
      "step 20400: mean loss = tf.Tensor(0.02653517, shape=(), dtype=float32)\n",
      "step 20500: mean loss = tf.Tensor(0.026470484, shape=(), dtype=float32)\n",
      "step 20600: mean loss = tf.Tensor(0.026431331, shape=(), dtype=float32)\n",
      "step 20700: mean loss = tf.Tensor(0.026368648, shape=(), dtype=float32)\n",
      "step 20800: mean loss = tf.Tensor(0.026305052, shape=(), dtype=float32)\n",
      "step 20900: mean loss = tf.Tensor(0.026272135, shape=(), dtype=float32)\n",
      "step 21000: mean loss = tf.Tensor(0.026218606, shape=(), dtype=float32)\n",
      "step 21100: mean loss = tf.Tensor(0.02618226, shape=(), dtype=float32)\n",
      "step 21200: mean loss = tf.Tensor(0.026166204, shape=(), dtype=float32)\n",
      "step 21300: mean loss = tf.Tensor(0.02614472, shape=(), dtype=float32)\n",
      "step 21400: mean loss = tf.Tensor(0.026147466, shape=(), dtype=float32)\n",
      "step 21500: mean loss = tf.Tensor(0.026157938, shape=(), dtype=float32)\n",
      "step 21600: mean loss = tf.Tensor(0.026184576, shape=(), dtype=float32)\n",
      "step 21700: mean loss = tf.Tensor(0.026213158, shape=(), dtype=float32)\n",
      "step 21800: mean loss = tf.Tensor(0.02621728, shape=(), dtype=float32)\n",
      "step 21900: mean loss = tf.Tensor(0.026192171, shape=(), dtype=float32)\n",
      "step 22000: mean loss = tf.Tensor(0.026171055, shape=(), dtype=float32)\n",
      "step 22100: mean loss = tf.Tensor(0.026151368, shape=(), dtype=float32)\n",
      "step 22200: mean loss = tf.Tensor(0.026122538, shape=(), dtype=float32)\n",
      "step 22300: mean loss = tf.Tensor(0.026103752, shape=(), dtype=float32)\n",
      "step 22400: mean loss = tf.Tensor(0.02612766, shape=(), dtype=float32)\n",
      "step 22500: mean loss = tf.Tensor(0.026148437, shape=(), dtype=float32)\n",
      "step 22600: mean loss = tf.Tensor(0.026180055, shape=(), dtype=float32)\n",
      "step 22700: mean loss = tf.Tensor(0.026191838, shape=(), dtype=float32)\n",
      "step 22800: mean loss = tf.Tensor(0.026221216, shape=(), dtype=float32)\n",
      "step 22900: mean loss = tf.Tensor(0.02624601, shape=(), dtype=float32)\n",
      "step 23000: mean loss = tf.Tensor(0.026275981, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23100: mean loss = tf.Tensor(0.026289888, shape=(), dtype=float32)\n",
      "step 23200: mean loss = tf.Tensor(0.026270686, shape=(), dtype=float32)\n",
      "step 23300: mean loss = tf.Tensor(0.026252037, shape=(), dtype=float32)\n",
      "step 23400: mean loss = tf.Tensor(0.026294768, shape=(), dtype=float32)\n",
      "step 23500: mean loss = tf.Tensor(0.02629201, shape=(), dtype=float32)\n",
      "step 23600: mean loss = tf.Tensor(0.026303582, shape=(), dtype=float32)\n",
      "step 23700: mean loss = tf.Tensor(0.026354393, shape=(), dtype=float32)\n",
      "step 23800: mean loss = tf.Tensor(0.026372401, shape=(), dtype=float32)\n",
      "step 23900: mean loss = tf.Tensor(0.026368355, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = SentimentBert(1)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "bce_loss= tf.keras.losses.MeanSquaredError()\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    total_loss = 0\n",
    "    for step, (bert_input, target) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "          output = model(bert_input)\n",
    "          # Compute reconstruction loss\n",
    "          loss = bce_loss(target, output)\n",
    "          loss += sum(model.losses)  # Add KLD regularization loss\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "          print('step %s: mean loss = %s' % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./bert_sentiment_analysis_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    # Give a sentence and return the sentiment score of the sentence\n",
    "    input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len=20)\n",
    "    tensor_input = tf.stack([tf.constant(input_ids), tf.constant(input_mask), tf.constant(segment_ids)])\n",
    "    tensor_input = tf.reshape(tensor_input, [1, 3, 20])\n",
    "    \n",
    "    return model(tensor_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5123083]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
